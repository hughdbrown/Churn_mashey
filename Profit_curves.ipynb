{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://mashey.io/wp-content/uploads/2016/02/Mashey-Logo.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Profit Curves Applied to Churn Prediction\n",
    "### Samuel Sherman"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have explored churn prediction and how it is of value to a business, I thought it might be important to introduce the idea of profit curves. As before, we were able to examine confusion matrices, which display how a model is performing amongst the different classes and the values that were mislabeled. You can imagine that no model will be perfect and that misclassification is a necessary evil. However, we can use this to our advantage. \n",
    "\n",
    "If we were to assign a dollar value that represents either a cost or beneifit associated with each type of classification, then we can iterate over different thresholds to determine what threshold and model are most valuable towards a company. As applied to churn, it would not make logical sense to invest time into customer retention just because a customer has a churn confidence of 51%. Therefore, having a higher threshold to classify churn is of greater value. With profit curves we will apply an algorithm to pinpoint the exact location of the threshold and model that produces the maximum benefit/profit.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import recall_score, precision_score, average_precision_score, roc_curve, roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression as LR\n",
    "from sklearn.ensemble import RandomForestClassifier as RF\n",
    "from sklearn.ensemble import GradientBoostingClassifier as GBC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.cross_validation import cross_val_score, StratifiedShuffleSplit, StratifiedKFold, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from unbalanced_dataset.over_sampling import SMOTE\n",
    "from unbalanced_dataset.under_sampling import UnderSampler\n",
    "from scipy import interp\n",
    "from scipy.io.arff import loadarff\n",
    "import xgboost as xgb\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "def prepare_data(filename):\n",
    "    churn = loadarff(filename)\n",
    "    churn_df = pd.DataFrame(churn[0])\n",
    "    \n",
    "    # Clean up categorical columns\n",
    "    churn_df['LEAVE'] = (churn_df['LEAVE'] == 'LEAVE').astype(int)\n",
    "    churn_df['COLLEGE'] = (churn_df['COLLEGE'] == \"one\").astype(int)\n",
    "    churn_df = pd.concat([churn_df,pd.get_dummies(churn_df.REPORTED_SATISFACTION)], axis = 1)\n",
    "    churn_df.drop('avg', axis = 1, inplace = True)\n",
    "    churn_df = pd.concat([churn_df,pd.get_dummies(churn_df.REPORTED_USAGE_LEVEL)], axis = 1)\n",
    "    churn_df.drop('avg', axis = 1, inplace = True)\n",
    "    churn_df = pd.concat([churn_df,pd.get_dummies(churn_df.CONSIDERING_CHANGE_OF_PLAN)], axis = 1)\n",
    "    churn_df.drop('never_thought', axis = 1, inplace = True)\n",
    "    churn_df.drop('REPORTED_SATISFACTION', axis = 1, inplace = True)\n",
    "    churn_df.drop('REPORTED_USAGE_LEVEL', axis = 1, inplace = True)\n",
    "    churn_df.drop('CONSIDERING_CHANGE_OF_PLAN', axis = 1, inplace = True)\n",
    "    \n",
    "    # set label array\n",
    "    y = churn_df.pop('LEAVE').values\n",
    "    \n",
    "    # set feature matrix\n",
    "    X = churn_df.values\n",
    "    \n",
    "    # Train test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 2)\n",
    "    \n",
    "    # Scale data\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I first define the same function that I defined before. It will read the data, extract the appropriate columns, dummify the categorical columns, normalize the data, and return the dependent and independent variables as separate training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def standard_confusion_matrix(y_true, y_predict):\n",
    "    [[tn, fp], [fn, tp]] = confusion_matrix(y_true, y_predict)\n",
    "    return np.array([[tp, fp], [fn, tn]])\n",
    "\n",
    "\n",
    "def profit_curve(cost_benefit_matrix, probabilities, y_true):\n",
    "    thresholds = sorted(probabilities)\n",
    "    thresholds.append(1.0)\n",
    "    profits = []\n",
    "    for threshold in thresholds:\n",
    "        y_predict = probabilities >= threshold\n",
    "        confusion_mat = standard_confusion_matrix(y_true, y_predict)\n",
    "        profit = np.sum(confusion_mat * cost_benefit_matrix) / float(len(y_true))\n",
    "        profits.append(profit)\n",
    "    return thresholds, profits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next two functions will build the confusion matrix and the profit curve. The confusion matrix will take in the real and predicted values and determine how many values are assoicated with each of the four confusion matrix components (true positive, true negative, false positive, false negative). The profit curve function will take the cost benefit matrix, a set of probabilities, and their true labels. It will iterate through the different probabilities for classifying what will be a one or zero and calculate a total profit for each iteration.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_profit_curve(model, costbenefit, X_train, X_test, y_train, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    probabilities = model.predict_proba(X_test)[:, 1]\n",
    "    thresholds, profits = profit_curve(costbenefit, probabilities, y_test)\n",
    "    return thresholds, profits\n",
    "\n",
    "\n",
    "def plot_profit_models(models, costbenefit, X_train, X_test, y_train, y_test):\n",
    "    percentages = np.linspace(0, 100, len(y_test) + 1)\n",
    "    profit_dict = {}\n",
    "    for model in models:\n",
    "        thresholds, profits = run_profit_curve(model,\n",
    "                                               costbenefit,\n",
    "                                               X_train, X_test,\n",
    "                                               y_train, y_test)\n",
    "        profit_dict['thresholds'] = thresholds\n",
    "        profit_dict[str(model)[:12]] = profits\n",
    "    return profit_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run_profit_curve will take a given model, train the model, determine the predicted probabilities, and then use these values to build the profit curve from the previous function. The next function will take a set of different models, the cost benefit matrix and the training and testing data and build the profit curves for each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_best_threshold(models, costbenefit, X_train, X_test, y_train, y_test):\n",
    "    max_model = None\n",
    "    max_threshold = None\n",
    "    max_profit = None\n",
    "    for model in models:\n",
    "        thresholds, profits = run_profit_curve(model, costbenefit,\n",
    "                                               X_train, X_test,\n",
    "                                               y_train, y_test)\n",
    "        max_index = np.argmax(profits)\n",
    "        if not max_model or profits[max_index] > max_profit:\n",
    "            max_model = model.__class__.__name__\n",
    "            max_threshold = thresholds[max_index]\n",
    "            max_profit = profits[max_index]\n",
    "    return max_model, max_threshold, max_profit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the find_best_threshold function will take the same data from the previous function and find the threshold and model associated with the highest possible profit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    X_train, X_test, y_train, y_test = prepare_data('data/churn.arff')\n",
    "    costbenefit = np.array([[80, -70], [-10, 0]])\n",
    "    models = [RF(random_state = 2, n_estimators = 100, n_jobs = -1), \n",
    "              LR(random_state = 2, n_jobs = -1), \n",
    "              xgb.XGBClassifier(learning_rate = 0.01, max_depth = 5, n_estimators = 500), \n",
    "              SVC(probability=True)]\n",
    "    profit_dict = plot_profit_models(models, costbenefit,\n",
    "                       X_train, X_test, y_train, y_test)\n",
    "    max_model, max_threshold, max_profit = find_best_threshold(models, costbenefit,\n",
    "                              X_train, X_test, y_train, y_test)\n",
    "    return max_model, max_threshold, max_profit, profit_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I use this function to pull together everything that I defined before. In this case I am using a random forest model, a logistic regresssion model, a gradient boosted model from xgboost, and support vector machine. It will return the the model and threshold associated with the max profit, the max profit, and dictionary of profits for all thresholds in each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_model, max_threshold, max_profit, profit_dict = main()\n",
    "profit_df = pd.DataFrame.from_dict(profit_dict)\n",
    "thresholds = profit_df.pop('thresholds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\"seamless=\"seamless\" src=\"https://plot.ly/~scsherm/132.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "import plotly.tools as tls\n",
    "py.sign_in('scsherm', 'ml0wer7f1s')\n",
    "\n",
    "data = []\n",
    "for model in profit_df.columns.values:\n",
    "    profit_vals = go.Scatter(x = thresholds, y = profit_df[model], mode = 'lines', name = model)\n",
    "    data.append(profit_vals)\n",
    "    \n",
    "layout = go.Layout(\n",
    "    title='Profit Curve per Model',\n",
    "    xaxis=dict(\n",
    "        title='Threshold',\n",
    "        titlefont=dict(\n",
    "            family='Courier New, monospace',\n",
    "            size=18,\n",
    "            color='#7f7f7f'\n",
    "        )\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title='Profit',\n",
    "        titlefont=dict(\n",
    "            family='Courier New, monospace',\n",
    "            size=18,\n",
    "            color='#7f7f7f'\n",
    "        )\n",
    "    )\n",
    ")\n",
    "Profit_Curve = go.Figure(data=data, layout=layout)    \n",
    "py.iplot(Profit_Curve, filename='Profit_Curve')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('XGBClassifier', 0.34050757, 17.737500000000001)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_model, max_threshold, max_profit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observing the graph above, you can see that the best model was the gradient boosted at a threshold of 34%, with an associated profit of 17.7. A do nothing approach would be similar to classifying everything as a zero or having a threshold of 100%. Well we can see that the do nothing approach, with the threshold 1 on the graph, has a profit of -5. Therefore, we can conclude that, on the other end of the spectrum, classifying everything as one (threshold 0), already provides a substantial improvement from doing nothing. I would claim that this is justification in itself for using this type of algorithm to give your company a competitive edge.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "\n",
       "html {\n",
       "  font-size: 62.5% !important; }\n",
       "body {\n",
       "  font-size: 1.5em !important; /* currently ems cause chrome bug misinterpreting rems on body element */\n",
       "  line-height: 1.6 !important;\n",
       "  font-weight: 400 !important;\n",
       "  font-family: \"Raleway\", \"HelveticaNeue\", \"Helvetica Neue\", Helvetica, Arial, sans-serif !important;\n",
       "  color: #222 !important; }\n",
       "\n",
       "div{ border-radius: 0px !important;  }\n",
       "div.CodeMirror-sizer{ background: rgb(244, 244, 248) !important; }\n",
       "div.input_area{ background: rgb(244, 244, 248) !important; }\n",
       "\n",
       "div.out_prompt_overlay:hover{ background: rgb(244, 244, 248) !important; }\n",
       "div.input_prompt:hover{ background: rgb(244, 244, 248) !important; }\n",
       "\n",
       "h1, h2, h3, h4, h5, h6 {\n",
       "  color: #333 !important;\n",
       "  margin-top: 0 !important;\n",
       "  margin-bottom: 2rem !important;\n",
       "  font-weight: 300 !important; }\n",
       "h1 { font-size: 4.0rem !important; line-height: 1.2 !important;  letter-spacing: -.1rem !important;}\n",
       "h2 { font-size: 3.6rem !important; line-height: 1.25 !important; letter-spacing: -.1rem !important; }\n",
       "h3 { font-size: 3.0rem !important; line-height: 1.3 !important;  letter-spacing: -.1rem !important; }\n",
       "h4 { font-size: 2.4rem !important; line-height: 1.35 !important; letter-spacing: -.08rem !important; }\n",
       "h5 { font-size: 1.8rem !important; line-height: 1.5 !important;  letter-spacing: -.05rem !important; }\n",
       "h6 { font-size: 1.5rem !important; line-height: 1.6 !important;  letter-spacing: 0 !important; }\n",
       "\n",
       "@media (min-width: 550px) {\n",
       "  h1 { font-size: 5.0rem !important; }\n",
       "  h2 { font-size: 4.2rem !important; }\n",
       "  h3 { font-size: 3.6rem !important; }\n",
       "  h4 { font-size: 3.0rem !important; }\n",
       "  h5 { font-size: 2.4rem !important; }\n",
       "  h6 { font-size: 1.5rem !important; }\n",
       "}\n",
       "\n",
       "p {\n",
       "  margin-top: 0 !important; }\n",
       "  \n",
       "a {\n",
       "  color: #1EAEDB !important; }\n",
       "a:hover {\n",
       "  color: #0FA0CE !important; }\n",
       "  \n",
       "code {\n",
       "  padding: .2rem .5rem !important;\n",
       "  margin: 0 .2rem !important;\n",
       "  font-size: 90% !important;\n",
       "  white-space: nowrap !important;\n",
       "  background: #F1F1F1 !important;\n",
       "  border: 1px solid #E1E1E1 !important;\n",
       "  border-radius: 4px !important; }\n",
       "pre > code {\n",
       "  display: block !important;\n",
       "  padding: 1rem 1.5rem !important;\n",
       "  white-space: pre !important; }\n",
       "  \n",
       "button{ border-radius: 0px !important; }\n",
       ".navbar-inner{ background-image: none !important;  }\n",
       "select, textarea{ border-radius: 0px !important; }\n",
       "\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.core.display import HTML\n",
    "import urllib2\n",
    "HTML(urllib2.urlopen('http://bit.ly/1Bf5Hft').read())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
